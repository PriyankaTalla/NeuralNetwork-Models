## Below are the list of NeuralNetwork-Models covered in this repository with examples

1. Perceptron
Concepts: Linear classification, binary decision boundary.
Mathematical Topics:
Linear Algebra: Dot product, weights.
Optimization: Gradient descent.
Example: Binary classification of linearly separable data.

2. Feedforward Neural Network (FNN)
Concepts: Layers, activation functions, forward propagation.
Mathematical Topics:
Linear Algebra: Matrix multiplications.
Optimization: Gradient descent, backpropagation.
Example: Predicting house prices based on multiple features.

3. Convolutional Neural Network (CNN)
Concepts: Convolutional layers, pooling layers, feature extraction.
Mathematical Topics:
Linear Algebra: Convolutions, filters.
Optimization: Backpropagation.
Example: Image classification (e.g., MNIST digit recognition).

4. Recurrent Neural Network (RNN)
Concepts: Sequence processing, hidden states.
Mathematical Topics:
Linear Algebra: Matrix multiplications.
Optimization: Backpropagation through time (BPTT).
Example: Predicting the next word in a sentence.

5. Long Short-Term Memory (LSTM)
Concepts: Memory cells, gates (input, forget, output).
Mathematical Topics:
Linear Algebra: Matrix multiplications.
Optimization: Backpropagation through time (BPTT).
Example: Predicting stock prices based on historical data.

6. Gated Recurrent Unit (GRU)
Concepts: Simplified LSTM, gates (reset, update).
Mathematical Topics:
Linear Algebra: Matrix multiplications.
Optimization: Backpropagation through time (BPTT).
Example: Sentiment analysis of text data.

7. Transformer
Concepts: Attention mechanisms, self-attention.
Mathematical Topics:
Linear Algebra: Dot product, softmax.
Optimization: Adam optimizer.
Example: Machine translation (e.g., translating English to French).

